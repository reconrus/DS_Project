{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVGcr9jSPaVM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJECT_PATH'] = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQtPdn2nPaVU"
   },
   "source": [
    "**Mount Google Drive** \n",
    "Tokenization will not work due to Perl script usage"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-wWLCVDPaVW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "os.environ['PROJECT_PATH']='/content/ydrive/My Drive/Study/DS_Project'\n",
    "drive.mount('/content/ydrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgoNDMrfPaVa"
   },
   "outputs": [],
   "source": [
    "os.environ['TOOLS']= os.path.join(os.environ['PROJECT_PATH'], 'tools')\n",
    "os.environ['RESOURCES']= os.path.join(os.environ['PROJECT_PATH'], 'resources')\n",
    "os.environ['DATA']= os.path.join(os.environ['RESOURCES'], 'data')\n",
    "os.environ['MODELS']= os.path.join(os.environ['PROJECT_PATH'], 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1IEhR76PaVg"
   },
   "source": [
    "## Download data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bashkir language"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAFnrBfLPaVi",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "BASHKIR=\"$DATA/bashkir\"\n",
    "git clone https://github.com/nevmenandr/bashkir-corpus \"$BASHKIR-corpus\"\n",
    "mkdir \"$BASHKIR\" & mkdir \"$BASHKIR/raw\"\n",
    "find \"$BASHKIR-corpus\" -name \"*.txt\" -print0 | xargs -0 -I file cat file > \"$BASHKIR/ba\"\n",
    "rm -rf -d  \"$BASHKIR-corpus\"\n",
    "\n",
    "WIKIEXTRACTOR=\"$TOOLS/wikiextractor\"\n",
    "git clone https://github.com/ptakopysk/wikiextractor \"$WIKIEXTRACTOR\"\n",
    "wget http://download.wikimedia.org/bawiki/latest/bawiki-latest-pages-articles.xml.bz2 -P \"$BASHKIR\"\n",
    "\"$WIKIEXTRACTOR/WikiExtractor.py\"  --json -o \"$BASHKIR/ba_wiki\" \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\"\n",
    "rm \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_folder = os.path.join(os.environ['DATA'], 'bashkir', 'ba_wiki')\n",
    "output_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
    "\n",
    "output_file = open(output_path, \"a+\", encoding='utf-8')\n",
    "\n",
    "for path, subdirs, files in os.walk(input_folder):\n",
    "    for name in files:\n",
    "        file = open(os.path.join(path, name), 'r', encoding='utf-8')\n",
    "        for line in file.readlines():\n",
    "            dump = json.loads(line)\n",
    "            output_file.write(\"%s\\n\" % dump[\"text\"])\n",
    "        file.close()\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "!rm -rf -d \"$DATA/bashkir/ba_wiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install razdel\n",
    "from razdel import sentenize\n",
    "\n",
    "raw_data_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
    "sentenized_data_path = os.path.join(os.environ['DATA'], 'ba.sentesized')\n",
    "\n",
    "raw_data = open(raw_data_path, 'r', encoding='utf-8')\n",
    "sentenized_data = open(sentenized_data_path, 'w+', encoding='utf-8')\n",
    "\n",
    "for line in raw_data:\n",
    "    sentences = sentenize(line)\n",
    "    sentenized_data.writelines([\"%s\\n\" % sentence.text for sentence in sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian language"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://data.statmt.org/wmt17/translation-task/news.2016.ru.shuffled.gz -P \"$DATA\"\n",
    "!gzip -d \"$DATA/news.2016.ru.shuffled.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuxEswhD2CvL"
   },
   "source": [
    "## Preprocessing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['L1']='ba'\n",
    "os.environ['L2']='ru'\n",
    "os.environ['L1_DATA']=\"ba.sentesized\"  \n",
    "os.environ['L2_DATA']=\"news.2016.ru.shuffled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW5yovpH3MAn"
   },
   "source": [
    "### Text cleaning and tokenization"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sacremoses\n",
    "from sacremoses import MosesPunctNormalizer, MosesTokenizer\n",
    "\n",
    "def preprocess_file(filepath, language):\n",
    "    normalizer = MosesPunctNormalizer(language, pre_replace_unicode_punct=True, post_remove_control_chars=True)\n",
    "    tokenizer = MosesTokenizer(language)\n",
    "    output_file = open('%s.cleaned' % filepath, 'w+', encoding='utf-8')\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as input_file:\n",
    "        for line in input_file:\n",
    "            line = normalizer.normalize(line)\n",
    "            tokens = tokenizer.tokenize(line)\n",
    "            output_file.write(\"{}\\n\".format(' '.join(tokens)))\n",
    "\n",
    "\n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L1_DATA']), os.environ['L1']) \n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L2_DATA']), os.environ['L2']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8tAgafPPaVy"
   },
   "source": [
    "### BPE codes generating"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9mLvL5OPaV0"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "FASTBPE=\"$TOOLS/fastBPE\"\n",
    "FAST=\"$FASTBPE/fast\"\n",
    "git clone https://github.com/glample/fastBPE \"$FASTBPE\"\n",
    "\n",
    "g++ -std=c++11 -pthread -O3 \"$FASTBPE/main.cc\" -IfastBPE -o \"$FAST\"\n",
    "\"$FAST\" learnbpe 40000 \"$DATA/${L1_DATA}.cleaned\" \"$DATA/${L2_DATA}.cleaned\" > \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"$DATA/${L1_DATA}.40000\" \"$DATA/${L1_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"$DATA/${L2_DATA}.40000\" \"$DATA/${L2_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
    "\n",
    "### Vocabulary will be calculated after dataset loading\n",
    "# \"$FAST\" getvocab \"$DATA/${L1_DATA}.40000\" > \"$DATA/vocab.${L1_DATA}.40000\" \n",
    "# \"$FAST\" getvocab \"$DATA/${L2_DATA}.40000\" > \"$DATA/vocab.${L2_DATA}.40000\" \n",
    "\n",
    "# TODO Add splitting data on train, valid and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKR2NM2JOxSe"
   },
   "source": [
    "### N-gram Translation Table Inferring"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSLATION_TABLE'] = os.path.join(os.environ['RESOURCES'], 'translation_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWs7DxH_PIPm"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "[ -f $RESOURCES/cc.ba.300.vec ] || wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ba.300.vec.gz -P  \"$TRANSLATION_TABLE\"\n",
    "[ -f $RESOURCES/cc.ru.300.vec ] || wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz -P \"$TRANSLATION_TABLE\"\n",
    "gzip -d \"$RESOURCES/cc.ba.300.vec.gz\"\n",
    "gzip -d \"$RESOURCES/cc.ru.300.vec.gz\"\n",
    "git clone https://github.com/artetxem/vecmap.git \"$TOOLS/vecmap\"\n",
    "python3 \"$TOOLS/vecmap/map_embeddings.py\" --unsupervised \"$TRANSLATION_TABLE/cc.ba.300.vec\" \"$TRANSLATION_TABLE/cc.ru.300.vec\" \"$TRANSLATION_TABLE/ba_mapped.vec\" \"$TRANSLATION_TABLE/ru_mapped.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install sklearn\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "l1_embs = \"ba_mapped.vec\"\n",
    "l2_embs = \"ru_mapped.vec\"\n",
    "\n",
    "l1_path=os.path.join(os.environ[\"TRANSLATION_TABLE\"], l1_embs)\n",
    "l2_path=os.path.join(os.environ[\"TRANSLATION_TABLE\"], l2_embs)\n",
    "\n",
    "l1_mapping = KeyedVectors.load_word2vec_format(l1_path)\n",
    "l2_mapping = KeyedVectors.load_word2vec_format(l2_path)\n",
    "\n",
    "vectors_loading_time = time.time()\n",
    "print('Loading vectors time: ', timedelta(seconds=vectors_loading_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ROWS_IN_SLICE = 15\n",
    "SAVE_EVERY_N_ROWS = 50\n",
    "K_NN = 5 \n",
    "\n",
    "translation_table_file_path = os.path.join(os.environ[\"TRANSLATION_TABLE\"], \"translation_table\") \n",
    "translation_table_file = open(translation_table_file_path, 'ab+') # will store array of vectors of l2 and size (#l1_vectors, K_NN)  \n",
    "\n",
    "\n",
    "def calculate_denominator_part(source_vectors, target_mapping, filename=None):\n",
    "    if filename:\n",
    "        f = open(filename, 'ab+')\n",
    "        last_saved = open('%s_index' % filename, 'w+')\n",
    "        start_index_to_save = 0\n",
    "    \n",
    "    result = np.empty(source_vectors.shape[0])\n",
    "    for i, vector in enumerate(tqdm(source_vectors)):\n",
    "        similar_vectors = target_mapping.similar_by_vector(vector, topn=K_NN)\n",
    "        result[i] = sum([similar_vector[1] for similar_vector in similar_vectors]) # similar_vector[1] is cosine distance \n",
    "        if filename and i % SAVE_EVERY_N_ROWS == 0:\n",
    "            np.savetxt(f, result[start_index_to_save:i+1])\n",
    "            start_index_to_save = i + 1\n",
    "            last_saved.write(str(i))\n",
    "    \n",
    "    if filename:\n",
    "        np.save(f, result[start_index_to_save:i+1])\n",
    "        f.close()\n",
    "    return result/(2*K_NN)\n",
    "\n",
    "start_time = time.time()\n",
    "l2_denominator_file_path = os.path.join(os.environ[\"TRANSLATION_TABLE\"], \"l2_denominator\") \n",
    "if os.path.exists(l2_denominator_file_path):\n",
    "    l2_denominator = np.loadtext(l2_denominator_file_path)\n",
    "    print(\"L2 denominator has been loaded from \", l2_denominator_file_path)    \n",
    "else:\n",
    "    l2_denominator = calculate_denominator_part(l2_mapping.vectors, l1_mapping, \"%s_backup\" % l2_denominator_file_path)\n",
    "    np.savetxt(l2_denominator_file_path, l2_denominator)\n",
    "    print(\"L2 denominator calculation time: \", timedelta(seconds=time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for slice_start in tqdm(range(0, l1_mapping.vectors.shape[0], ROWS_IN_SLICE)):\n",
    "    slice_end = slice_start + ROWS_IN_SLICE\n",
    "    slice_end = slice_end if slice_end < l1_mapping.vectors.shape[0] else l1_mapping.vectors.shape[0]\n",
    "    l1_slice = l1_mapping.vectors[slice_start:slice_end]\n",
    "\n",
    "    cos_sims = cosine_similarity(l1_slice, l2_mapping.vectors)    \n",
    "    \n",
    "    l1_denominator = calculate_denominator_part(l1_slice, l2_mapping)\n",
    "\n",
    "    denominator = l1_denominator[:, None] + l2_denominator\n",
    "    \n",
    "    similarities = cos_sims/denominator\n",
    "\n",
    "    most_similar_indices = similarities.argsort(axis=1)[:, -K_NN:] \n",
    "    most_similar = np.take(l2_mapping.vectors, most_similar_indices) \n",
    "\n",
    "    np.savetxt(translation_table_file, most_similar)\n",
    "    \n",
    "translation_table_file.close()\n",
    "print(\"Translation table inferring time: \", timedelta(seconds=time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGIdhpFGvvil"
   },
   "source": [
    "## Model implementation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykOAbsio60I6"
   },
   "source": [
    "### Tools"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwfdjGo6Wvw-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#src https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owkE0F9fFSBW"
   },
   "source": [
    "### BaseModel\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WY8LLAnjI_b"
   },
   "source": [
    "Temporarily hyperparameters are hardcoded for better readability \n",
    "\n",
    "\n",
    "Sources:\n",
    "1. https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "2. https://github.com/facebookresearch/XLM/blob/master/src/model/transformer.py\n",
    "3. https://discuss.pytorch.org/t/memory-mask-in-nn-transformer/55230/5\n",
    "4. https://github.com/tkmaroon/pytorch-xlm/blob/master/models/transformer.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z523fnIeFRhd"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, \\\n",
    "                     TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, field, d_model=1024, nlayers=6, nheads=8, dropout=0.1):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        # [4]\n",
    "        self.voc_size = len(field.vocab.itos) \n",
    "        self.pad_idx = field.vocab.stoi['<pad>']\n",
    "        self.bos_idx = field.vocab.stoi['<bos>']\n",
    "        self.eos_idx = field.vocab.stoi['<eos>']\n",
    "        self.sep_idx = field.vocab.stoi['<sep>']\n",
    "        self.mask_idx = field.vocab.stoi['<mask>']\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(self.voc_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nheads, dim_feedforward=4*d_model, activation='gelu')\n",
    "        self.encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.normal_(self.embedding.weight, mean=0, std=self.d_model ** -0.5) #[2] L46\n",
    "\n",
    "    def forward(self, src):\n",
    "        pad_mask = torch.transpose(src.eq(self.pad_idx), 0, 1)\n",
    "        src_mask = self.get_mask(src, pad_mask)\n",
    "        src = self.embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        src = self.encoder(src)\n",
    "        src = F.dropout(src, self.dropout, training=self.training)\n",
    "\n",
    "        output = self.encoder(src, src_mask, pad_mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def get_mask(self, inputs, pad_mask): #[2]\n",
    "        slen, bs = inputs.size()\n",
    "        lengths = slen-torch.sum(pad_mask, 0)\n",
    "\n",
    "        alen = torch.arange(slen, dtype=torch.long, device=lengths.device)\n",
    "\n",
    "        return alen < lengths[:, None]\n",
    "\n",
    "    # [4]\n",
    "    def mlm_loss(self, inputs, criterion, sampling_rate=0.15, masked_rate=0.8, replaced_rate=0.1, unchanged_rate=0.1):\n",
    "        slen, bs = inputs.size()\n",
    "\n",
    "        sampler = self.sampling(inputs, sampling_rate)\n",
    "        rnd = torch.rand((slen, bs), device=inputs.device)\n",
    "        mask = (masked_rate >= rnd) & sampler\n",
    "\n",
    "        # replace mask tokens\n",
    "        inputs = torch.where(\n",
    "            (masked_rate >= rnd) & mask,\n",
    "            torch.ones_like(inputs) * self.mask_idx, \n",
    "            inputs,\n",
    "        )\n",
    "\n",
    "        # replace random tokens\n",
    "        th = masked_rate + replaced_rate\n",
    "        inputs = torch.where(\n",
    "            (th >= rnd) & (rnd > masked_rate) & sampler, \n",
    "            torch.randint_like(inputs, self.mask_idx+1, self.voc_size),\n",
    "            inputs\n",
    "        )\n",
    "\n",
    "        outs = self.forward(inputs).view(slen*bs, -1)\n",
    "        loss = criterion(outs, inputs.view(-1))\n",
    "        return loss\n",
    "\n",
    "    # [4]\n",
    "    def sampling(self, inputs, sampling_rate):\n",
    "        slen, bs = inputs.size()\n",
    "        rnd = -torch.rand((slen, bs))\n",
    "        mask = rnd.ge(-sampling_rate)\n",
    "        mask[inputs <= self.mask_idx] = 0 # special tokens are not sampled\n",
    "        return mask.to(inputs.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSSoHD9rNX_5"
   },
   "source": [
    "### Pretraining"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSpdyLWxNbXW"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext==0.5.0\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, clip, n_iter=0):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.clip = clip\n",
    "        self.n_updates = n_iter\n",
    "\n",
    "    def get_lr(self):\n",
    "        return self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "    def step(self, inputs):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.model.mlm_loss(inputs, self.criterion)\n",
    "\n",
    "        if self.model.training:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
    "            self.optimizer.step()\n",
    "            self.n_updates += 1\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def pretrain(data_path, device, min_vocab_freq=1, batch_size=64, sequence_length=256, lr=0.25, clip=1.0, n_epoch=40, save_epoch=2):\n",
    "\n",
    "    TEXT = data.Field(\n",
    "        init_token='<bos>', \n",
    "        eos_token='<eos>',\n",
    "    )\n",
    "\n",
    "    train_dataset = datasets.LanguageModelingDataset(data_path, TEXT)\n",
    "\n",
    "    vocab = TEXT.build_vocab(\n",
    "        train_dataset, \n",
    "        min_freq=min_vocab_freq, \n",
    "        specials=['<sep>', '<mask>']\n",
    "    )\n",
    "    train_iter = data.BPTTIterator(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        bptt_len=256,\n",
    "        train=True, \n",
    "        repeat=False, \n",
    "        shuffle=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(os.environ['MODELS']):\n",
    "        os.mkdir(os.environ['MODELS'])\n",
    "    \n",
    "    model = BaseModel(TEXT).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    best_loss = math.inf\n",
    "    epoch=0\n",
    "    trainer = Trainer(model, criterion, optimizer, clip)\n",
    "\n",
    "    while epoch <= n_epoch:\n",
    "        # training\n",
    "        with tqdm(train_iter, dynamic_ncols=True) as pbar:\n",
    "            train_loss = 0.0\n",
    "            model.train()\n",
    "            for samples in pbar:\n",
    "                srcs = samples.text.to(device)\n",
    "                loss = trainer.step(srcs)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # setting of progressbar\n",
    "                pbar.set_description(f'epoch {str(epoch).zfill(3)}')\n",
    "                progress_state = OrderedDict(\n",
    "                    loss=loss.item(),\n",
    "                    bsz=srcs.size(1),\n",
    "                    lr=trainer.get_lr(), \n",
    "                    clip=clip, \n",
    "                    num_updates=trainer.n_updates)\n",
    "                pbar.set_postfix(progress_state)\n",
    "        train_loss /= len(train_iter)\n",
    "\n",
    "        print(f'| epoch {str(epoch).zfill(3)} | train ', end='') \n",
    "        print(f'| loss {train_loss:.{4}} ', end='')\n",
    "        print(f'| lr {trainer.get_lr():.1e} ', end='')\n",
    "        print(f'| clip {clip} ', end='')\n",
    "        print(f'| num_updates {trainer.n_updates} |')\n",
    "        \n",
    "        # saving model\n",
    "        save_vars = {\n",
    "            'epoch': epoch,\n",
    "            'iteration': trainer.n_updates,\n",
    "            'best_loss': train_loss if train_loss < best_loss else best_loss,\n",
    "            'weights': model.state_dict()\n",
    "        }\n",
    "\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            filename = os.path.join(os.environ['MODELS'], 'checkpoint_best.pt') \n",
    "            torch.save(save_vars, filename)\n",
    "        if epoch % save_epoch == 0:\n",
    "            filename = os.path.join(os.environ['MODELS'], f'checkpoint_{epoch}.pt') \n",
    "            torch.save(save_vars, filename)\n",
    "        filename = os.path.join(os.environ['MODELS'], 'checkpoint_last.pt') \n",
    "        torch.save(save_vars, filename)\n",
    "\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeiC8PqvPaWL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}