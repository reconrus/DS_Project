{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CVGcr9jSPaVM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PROJECT_PATH'] = os.path.abspath(os.curdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQtPdn2nPaVU"
      },
      "source": [
        "**Mount Google Drive** \n",
        "Tokenization will not work due to Perl script usage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "R-wWLCVDPaVW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "os.environ['PROJECT_PATH']='/content/ydrive/My Drive/Study/DS_Project'\n",
        "drive.mount('/content/ydrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dgoNDMrfPaVa"
      },
      "outputs": [],
      "source": [
        "os.environ['TOOLS']= os.path.join(os.environ['PROJECT_PATH'], 'tools')\n",
        "os.environ['RESOURCES']= os.path.join(os.environ['PROJECT_PATH'], 'resources')\n",
        "os.environ['DATA']= os.path.join(os.environ['RESOURCES'], 'data')\n",
        "os.environ['MODELS']= os.path.join(os.environ['PROJECT_PATH'], 'models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1IEhR76PaVg"
      },
      "source": [
        "## Download data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bashkir language"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oAFnrBfLPaVi",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "BASHKIR=\"$DATA/bashkir\"\n",
        "git clone https://github.com/nevmenandr/bashkir-corpus \"$BASHKIR-corpus\"\n",
        "mkdir \"$BASHKIR\" & mkdir \"$BASHKIR/raw\"\n",
        "find \"$BASHKIR-corpus\" -name \"*.txt\" -print0 | xargs -0 -I file cat file > \"$BASHKIR/ba\"\n",
        "rm -rf -d  \"$BASHKIR-corpus\"\n",
        "\n",
        "WIKIEXTRACTOR=\"$TOOLS/wikiextractor\"\n",
        "git clone https://github.com/ptakopysk/wikiextractor \"$WIKIEXTRACTOR\"\n",
        "wget http://download.wikimedia.org/bawiki/latest/bawiki-latest-pages-articles.xml.bz2 -P \"$BASHKIR\"\n",
        "\"$WIKIEXTRACTOR/WikiExtractor.py\"  --json -o \"$BASHKIR/ba_wiki\" \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\"\n",
        "rm \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_folder = os.path.join(os.environ['DATA'], 'bashkir', 'ba_wiki')\n",
        "output_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
        "\n",
        "output_file = open(output_path, \"a+\", encoding='utf-8')\n",
        "\n",
        "for path, subdirs, files in os.walk(input_folder):\n",
        "    for name in files:\n",
        "        file = open(os.path.join(path, name), 'r', encoding='utf-8')\n",
        "        for line in file.readlines():\n",
        "            dump = json.loads(line)\n",
        "            output_file.write(\"%s\\n\" % dump[\"text\"])\n",
        "        file.close()\n",
        "\n",
        "output_file.close()\n",
        "\n",
        "!rm -rf -d \"$DATA/bashkir/ba_wiki\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install razdel\n",
        "from razdel import sentenize\n",
        "\n",
        "raw_data_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
        "sentenized_data_path = os.path.join(os.environ['DATA'], 'ba.sentesized')\n",
        "\n",
        "raw_data = open(raw_data_path, 'r', encoding='utf-8')\n",
        "sentenized_data = open(sentenized_data_path, 'w+', encoding='utf-8')\n",
        "\n",
        "for line in raw_data:\n",
        "    sentences = sentenize(line)\n",
        "    sentenized_data.writelines([\"%s\\n\" % sentence.text for sentence in sentences])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Russian language"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://data.statmt.org/wmt17/translation-task/news.2016.ru.shuffled.gz -P \"$DATA\"\n",
        "!gzip -d \"$DATA/news.2016.ru.shuffled.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RuxEswhD2CvL"
      },
      "source": [
        "## Preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['L1']='ba'\n",
        "os.environ['L2']='ru'\n",
        "os.environ['L1_DATA']=\"ba.sentesized\"  \n",
        "os.environ['L2_DATA']=\"news.2016.ru.shuffled\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW5yovpH3MAn"
      },
      "source": [
        "### Text cleaning and tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U sacremoses\n",
        "from sacremoses import MosesPunctNormalizer, MosesTokenizer\n",
        "\n",
        "def preprocess_file(filepath, language):\n",
        "    normalizer = MosesPunctNormalizer(language, pre_replace_unicode_punct=True, post_remove_control_chars=True)\n",
        "    tokenizer = MosesTokenizer(language)\n",
        "    output_file = open('%s.cleaned' % filepath, 'w+', encoding='utf-8')\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as input_file:\n",
        "        for line in input_file:\n",
        "            line = normalizer.normalize(line)\n",
        "            tokens = tokenizer.tokenize(line)\n",
        "            output_file.write(\"{}\\n\".format(' '.join(tokens)))\n",
        "\n",
        "\n",
        "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L1_DATA']), os.environ['L1']) \n",
        "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L2_DATA']), os.environ['L2']) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8tAgafPPaVy"
      },
      "source": [
        "### BPE codes generating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "x9mLvL5OPaV0"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "FASTBPE=\"$TOOLS/fastBPE\"\n",
        "FAST=\"$FASTBPE/fast\"\n",
        "git clone https://github.com/glample/fastBPE \"$FASTBPE\"\n",
        "\n",
        "g++ -std=c++11 -pthread -O3 \"$FASTBPE/main.cc\" -IfastBPE -o \"$FAST\"\n",
        "\"$FAST\" learnbpe 40000 \"$DATA/${L1_DATA}.cleaned\" \"$DATA/${L2_DATA}.cleaned\" > \"$DATA/BPE_codes\"\n",
        "\"$FAST\" applybpe \"$DATA/${L1_DATA}.40000\" \"$DATA/${L1_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
        "\"$FAST\" applybpe \"$DATA/${L2_DATA}.40000\" \"$DATA/${L2_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
        "\n",
        "### Vocabulary will be calculated after dataset loading\n",
        "# \"$FAST\" getvocab \"$DATA/${L1_DATA}.40000\" > \"$DATA/vocab.${L1_DATA}.40000\" \n",
        "# \"$FAST\" getvocab \"$DATA/${L2_DATA}.40000\" > \"$DATA/vocab.${L2_DATA}.40000\" \n",
        "\n",
        "# TODO Add splitting data on train, valid and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKR2NM2JOxSe"
      },
      "source": [
        "### N-gram Translation Table Inferring"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cWs7DxH_PIPm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "[ -f $RESOURCES/cc.ba.300.vec ] || wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ba.300.vec.gz -P  \"$RESOURCES\"\n",
        "[ -f $RESOURCES/cc.ru.300.vec ] || wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz -P \"$RESOURCES\"\n",
        "gzip -d \"$RESOURCES/cc.ba.300.vec.gz\"\n",
        "gzip -d \"$RESOURCES/cc.ru.300.vec.gz\"\n",
        "git clone https://github.com/artetxem/vecmap.git \"$TOOLS/vecmap\"\n",
        "python3 \"$TOOLS/vecmap/map_embeddings.py\" --unsupervised \"$RESOURCES/cc.ba.300.vec\" \"$RESOURCES/cc.ru.300.vec\" \"$RESOURCES/ba_mapped.vec\" \"$RESOURCES/ru_mapped.vec\" \n",
        "# TODO add the table inferring from above cross-lingual embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: gensim in /home/hawk/.local/lib/python3.7/site-packages (3.5.0)\nRequirement already satisfied: numpy>=1.11.3 in /home/hawk/.local/lib/python3.7/site-packages (from gensim) (1.16.3)\nRequirement already satisfied: smart-open>=1.2.1 in /home/hawk/.local/lib/python3.7/site-packages (from gensim) (1.8.4)\nRequirement already satisfied: scipy>=0.18.1 in /home/hawk/.local/lib/python3.7/site-packages (from gensim) (1.1.0)\nRequirement already satisfied: six>=1.5.0 in /home/hawk/.local/lib/python3.7/site-packages (from gensim) (1.11.0)\nRequirement already satisfied: boto3 in /home/hawk/.local/lib/python3.7/site-packages (from smart-open>=1.2.1->gensim) (1.9.243)\nRequirement already satisfied: requests in /home/hawk/.local/lib/python3.7/site-packages (from smart-open>=1.2.1->gensim) (2.22.0)\nRequirement already satisfied: boto>=2.32 in /home/hawk/.local/lib/python3.7/site-packages (from smart-open>=1.2.1->gensim) (2.49.0)\nRequirement already satisfied: botocore<1.13.0,>=1.12.243 in /home/hawk/.local/lib/python3.7/site-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.243)\nRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/hawk/.local/lib/python3.7/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/hawk/.local/lib/python3.7/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/hawk/.local/lib/python3.7/site-packages (from requests->smart-open>=1.2.1->gensim) (1.25.3)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/hawk/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /home/hawk/.local/lib/python3.7/site-packages (from requests->smart-open>=1.2.1->gensim) (2.7)\nRequirement already satisfied: certifi>=2017.4.17 in /home/hawk/.local/lib/python3.7/site-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.13)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/hawk/.local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.243->boto3->smart-open>=1.2.1->gensim) (2.7.3)\nRequirement already satisfied: docutils<0.16,>=0.10 in /home/hawk/.local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.243->boto3->smart-open>=1.2.1->gensim) (0.15.2)\nRequirement already satisfied: sklearn in /home/hawk/anaconda3/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /home/hawk/.local/lib/python3.7/site-packages (from sklearn) (0.19.2)\n"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'KeyedVemappings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5e0b6987866b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0ml1_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0ml2_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVemappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mvectors_loading_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KeyedVemappings' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install sklearn\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "K_NN = 5 \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "l1_embs = \"ba_mapped.vec\"\n",
        "l2_embs = \"ru_mapped.vec\"\n",
        "\n",
        "l1_path=os.path.join(os.environ[\"RESOURCES\"], l1_embs)\n",
        "l2_path=os.path.join(os.environ[\"RESOURCES\"], l2_embs)\n",
        "\n",
        "l1_mapping = KeyedVectors.load_word2vec_format(l1_path)\n",
        "l2_mapping = KeyedVectors.load_word2vec_format(l2_path)\n",
        "\n",
        "vectors_loading_time = time.time()\n",
        "print('Loading vectors time: ', timedelta(seconds=vectors_loading_time - start_time))\n",
        "\n",
        "cos_sims = cosine_similarity(l1_mapping.vectors, l2_mapping.vectors)\n",
        "\n",
        "cosine_time = time.time()\n",
        "print(\"Cosine similarity calculation time: \", timedelta(seconds=cosine_time - vectors_loading_time))\n",
        "\n",
        "l1_to_n_l2_indices = cos_sims.argsort(axis=1)[:, -K_NN:] \n",
        "l2_to_n_l1_indices = cos_sims.argsort(axis=0)[-K_NN:, :]\n",
        "\n",
        "indices_time = time.time()\n",
        "print(\"Indices calculation time: \", timedelta(seconds=indices_time - cosine_time))\n",
        "\n",
        "l1_to_n_l2 = np.take_along_axis(cos_sims, l1_to_n_l2_indices, axis=1)\n",
        "l2_to_n_l1 = np.take_along_axis(cos_sims, l2_to_n_l1_indices, axis=0).T\n",
        "\n",
        "matrices_time = time.time()\n",
        "print(\"Matrices time: \", timedelta(seconds=matrices_time - indices_time))\n",
        "\n",
        "\n",
        "denominator_l1 = np.sum(l1_to_n_l2, axis=1)/(2*K_NN)\n",
        "denominator_l2 = np.sum(l2_to_n_l1, axis=1)/(2*K_NN)\n",
        "\n",
        "denominator = denominator_l1[:, None] + denominator_l2\n",
        "\n",
        "similarity_table = cos_sims/denominator\n",
        "\n",
        "print(\"Total time: \", timedelta(seconds=time_time() - matrices_time))\n",
        "\n",
        "\n",
        "np.savetxt(os.path.join(os.environ['RESOURCES'], 'similarity_table'), similarity_table)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGIdhpFGvvil"
      },
      "source": [
        "## Model implementation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ykOAbsio60I6"
      },
      "source": [
        "### Tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lwfdjGo6Wvw-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "#src https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "owkE0F9fFSBW"
      },
      "source": [
        "### BaseModel\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_WY8LLAnjI_b"
      },
      "source": [
        "Temporarily hyperparameters are hardcoded for better readability \n",
        "\n",
        "\n",
        "Sources:\n",
        "1. https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "2. https://github.com/facebookresearch/XLM/blob/master/src/model/transformer.py\n",
        "3. https://discuss.pytorch.org/t/memory-mask-in-nn-transformer/55230/5\n",
        "4. https://github.com/tkmaroon/pytorch-xlm/blob/master/models/transformer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z523fnIeFRhd"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerDecoder, TransformerDecoderLayer, \\\n",
        "                     TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, field, d_model=1024, nlayers=6, nheads=8, dropout=0.1):\n",
        "        super(BaseModel, self).__init__()\n",
        "        \n",
        "        # [4]\n",
        "        self.voc_size = len(field.vocab.itos) \n",
        "        self.pad_idx = field.vocab.stoi['<pad>']\n",
        "        self.bos_idx = field.vocab.stoi['<bos>']\n",
        "        self.eos_idx = field.vocab.stoi['<eos>']\n",
        "        self.sep_idx = field.vocab.stoi['<sep>']\n",
        "        self.mask_idx = field.vocab.stoi['<mask>']\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.dropout = dropout\n",
        "        self.embedding = nn.Embedding(self.voc_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nheads, dim_feedforward=4*d_model, activation='gelu')\n",
        "        self.encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.normal_(self.embedding.weight, mean=0, std=self.d_model ** -0.5) #[2] L46\n",
        "\n",
        "    def forward(self, src):\n",
        "        pad_mask = torch.transpose(src.eq(self.pad_idx), 0, 1)\n",
        "        src_mask = self.get_mask(src, pad_mask)\n",
        "        src = self.embedding(src)\n",
        "        src = self.pos_encoder(src)\n",
        "        src = self.encoder(src)\n",
        "        src = F.dropout(src, self.dropout, training=self.training)\n",
        "\n",
        "        output = self.encoder(src, src_mask, pad_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def get_mask(self, inputs, pad_mask): #[2]\n",
        "        slen, bs = inputs.size()\n",
        "        lengths = slen-torch.sum(pad_mask, 0)\n",
        "\n",
        "        alen = torch.arange(slen, dtype=torch.long, device=lengths.device)\n",
        "\n",
        "        return alen < lengths[:, None]\n",
        "\n",
        "    # [4]\n",
        "    def mlm_loss(self, inputs, criterion, sampling_rate=0.15, masked_rate=0.8, replaced_rate=0.1, unchanged_rate=0.1):\n",
        "        slen, bs = inputs.size()\n",
        "\n",
        "        sampler = self.sampling(inputs, sampling_rate)\n",
        "        rnd = torch.rand((slen, bs), device=inputs.device)\n",
        "        mask = (masked_rate >= rnd) & sampler\n",
        "\n",
        "        # replace mask tokens\n",
        "        inputs = torch.where(\n",
        "            (masked_rate >= rnd) & mask,\n",
        "            torch.ones_like(inputs) * self.mask_idx, \n",
        "            inputs,\n",
        "        )\n",
        "\n",
        "        # replace random tokens\n",
        "        th = masked_rate + replaced_rate\n",
        "        inputs = torch.where(\n",
        "            (th >= rnd) & (rnd > masked_rate) & sampler, \n",
        "            torch.randint_like(inputs, self.mask_idx+1, self.voc_size),\n",
        "            inputs\n",
        "        )\n",
        "\n",
        "        outs = self.forward(inputs).view(slen*bs, -1)\n",
        "        loss = criterion(outs, inputs.view(-1))\n",
        "        return loss\n",
        "\n",
        "    # [4]\n",
        "    def sampling(self, inputs, sampling_rate):\n",
        "        slen, bs = inputs.size()\n",
        "        rnd = -torch.rand((slen, bs))\n",
        "        mask = rnd.ge(-sampling_rate)\n",
        "        mask[inputs <= self.mask_idx] = 0 # special tokens are not sampled\n",
        "        return mask.to(inputs.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kSSoHD9rNX_5"
      },
      "source": [
        "### Pretraining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TSpdyLWxNbXW"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.5.0\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext import data, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, criterion, optimizer, clip, n_iter=0):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.clip = clip\n",
        "        self.n_updates = n_iter\n",
        "\n",
        "    def get_lr(self):\n",
        "        return self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "    def step(self, inputs):\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = self.model.mlm_loss(inputs, self.criterion)\n",
        "\n",
        "        if self.model.training:\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "            self.optimizer.step()\n",
        "            self.n_updates += 1\n",
        "        return loss\n",
        "    \n",
        "\n",
        "def pretrain(data_path, device, min_vocab_freq=1, batch_size=64, sequence_length=256, lr=0.25, clip=1.0, n_epoch=40, save_epoch=2):\n",
        "\n",
        "    TEXT = data.Field(\n",
        "        init_token='<bos>', \n",
        "        eos_token='<eos>',\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.LanguageModelingDataset(data_path, TEXT)\n",
        "\n",
        "    vocab = TEXT.build_vocab(\n",
        "        train_dataset, \n",
        "        min_freq=min_vocab_freq, \n",
        "        specials=['<sep>', '<mask>']\n",
        "    )\n",
        "    train_iter = data.BPTTIterator(\n",
        "        train_dataset, \n",
        "        batch_size=batch_size, \n",
        "        bptt_len=256,\n",
        "        train=True, \n",
        "        repeat=False, \n",
        "        shuffle=True,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if not os.path.exists(os.environ['MODELS']):\n",
        "        os.mkdir(os.environ['MODELS'])\n",
        "    \n",
        "    model = BaseModel(TEXT).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=TEXT.vocab.stoi['<pad>'])\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    best_loss = math.inf\n",
        "    epoch=0\n",
        "    trainer = Trainer(model, criterion, optimizer, clip)\n",
        "\n",
        "    while epoch <= n_epoch:\n",
        "        # training\n",
        "        with tqdm(train_iter, dynamic_ncols=True) as pbar:\n",
        "            train_loss = 0.0\n",
        "            model.train()\n",
        "            for samples in pbar:\n",
        "                srcs = samples.text.to(device)\n",
        "                loss = trainer.step(srcs)\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                # setting of progressbar\n",
        "                pbar.set_description(f'epoch {str(epoch).zfill(3)}')\n",
        "                progress_state = OrderedDict(\n",
        "                    loss=loss.item(),\n",
        "                    bsz=srcs.size(1),\n",
        "                    lr=trainer.get_lr(), \n",
        "                    clip=clip, \n",
        "                    num_updates=trainer.n_updates)\n",
        "                pbar.set_postfix(progress_state)\n",
        "        train_loss /= len(train_iter)\n",
        "\n",
        "        print(f'| epoch {str(epoch).zfill(3)} | train ', end='') \n",
        "        print(f'| loss {train_loss:.{4}} ', end='')\n",
        "        print(f'| lr {trainer.get_lr():.1e} ', end='')\n",
        "        print(f'| clip {clip} ', end='')\n",
        "        print(f'| num_updates {trainer.n_updates} |')\n",
        "        \n",
        "        # saving model\n",
        "        save_vars = {\n",
        "            'epoch': epoch,\n",
        "            'iteration': trainer.n_updates,\n",
        "            'best_loss': train_loss if train_loss < best_loss else best_loss,\n",
        "            'weights': model.state_dict()\n",
        "        }\n",
        "\n",
        "        if train_loss < best_loss:\n",
        "            best_loss = train_loss\n",
        "            filename = os.path.join(os.environ['MODELS'], 'checkpoint_best.pt') \n",
        "            torch.save(save_vars, filename)\n",
        "        if epoch % save_epoch == 0:\n",
        "            filename = os.path.join(os.environ['MODELS'], f'checkpoint_{epoch}.pt') \n",
        "            torch.save(save_vars, filename)\n",
        "        filename = os.path.join(os.environ['MODELS'], 'checkpoint_last.pt') \n",
        "        torch.save(save_vars, filename)\n",
        "\n",
        "        epoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yeiC8PqvPaWL"
      },
      "outputs": [],
      "source": []
    }
  ]
}