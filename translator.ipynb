{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srF9AmoNjloE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJECT_PATH'] = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzEsS8lkjnSW"
   },
   "source": [
    "**Mount Google Drive**\n",
    "\n",
    "It looks like it is impossible to use Google Colab, since I am using torchtext package, where field.build_vocab method is broken for the latest version supported by python3.6, while in python3.7 everything is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "6iQRfEmrjmR_",
    "outputId": "100a81eb-0e03-4943-ac20-9d696df4d484"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "os.environ['PROJECT_PATH']='/content/ydrive/My Drive/Study/UNMT'\n",
    "drive.mount('/content/ydrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g02rnRLKjmP5"
   },
   "outputs": [],
   "source": [
    "os.environ['TOOLS']= os.path.join(os.environ['PROJECT_PATH'], 'tools')\n",
    "os.environ['RESOURCES']= os.path.join(os.environ['PROJECT_PATH'], 'resources')\n",
    "os.environ['DATA']= os.path.join(os.environ['RESOURCES'], 'data')\n",
    "os.environ['MODELS']= os.path.join(os.environ['PROJECT_PATH'], 'models')\n",
    "\n",
    "# DATA VARIABLES\n",
    "os.environ['VOCAB_SIZE']=\"32000\"\n",
    "os.environ['L1']='ba'\n",
    "os.environ['L2']='ru'\n",
    "os.environ['L1_DATA']=\"ba.sentesized\"  \n",
    "os.environ['L2_DATA']=\"news.2016.ru.shuffled\"\n",
    "os.environ['L1_DATA_PREPARED']=os.path.join(os.environ['DATA'], \"{}.{}\".format(os.environ['L1_DATA'], os.environ['VOCAB_SIZE']))\n",
    "os.environ['L2_DATA_PREPARED']=os.path.join(os.environ['DATA'], \"{}.{}\".format(os.environ['L2_DATA'], os.environ['VOCAB_SIZE']))\n",
    "\n",
    "os.environ[\"EMBEDDINGS_DIR\"]=os.path.join(os.environ[\"RESOURCES\"], \"embeddings\")\n",
    "os.environ[\"BPE_EMBEDDINGS\"]=\"{}-{}-bpe\".format(os.environ['L1'], os.environ['L2'])\n",
    "\n",
    "os.environ['L1_DATA_PARALLEL_RAW']=\"raw.parallel.{}\".format(os.environ['L1'])\n",
    "os.environ['L2_DATA_PARALLEL_RAW']=\"raw.parallel.{}\".format(os.environ['L2'])\n",
    "os.environ['L1_DATA_PARALLEL']=\"parallel.{}\".format(os.environ['L1'])\n",
    "os.environ['L2_DATA_PARALLEL']=\"parallel.{}\".format(os.environ['L2'])\n",
    "os.environ['PARALLEL_PREFIX']=os.path.join(os.environ['DATA'], \"parallel.{}.\".format(os.environ['VOCAB_SIZE']))\n",
    "os.environ['L1_DATA_PARALLEL_PREPARED']='{}{}'.format(os.environ['PARALLEL_PREFIX'], os.environ['L1'])\n",
    "os.environ['L2_DATA_PARALLEL_PREPARED']='{}{}'.format(os.environ['PARALLEL_PREFIX'], os.environ['L2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th28wv8si8DZ"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWusp5EeNWir"
   },
   "source": [
    "## Parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bzwj5hSdNVfu"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget \"https://docs.google.com/uc?export=download&id=1CQnKby8igxidqC3DqC0RRBJ0mfdyQ-T1\" --output-document=$DATA/$L1_DATA_PARALLEL_RAW\n",
    "wget \"https://docs.google.com/uc?export=download&id=1ikD6di7XiR3pWO72aVFbn9HK4-q0Iskb\" --output-document=$DATA/$L2_DATA_PARALLEL_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv568vkYjBfh"
   },
   "source": [
    "## Bashkir Language (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aMb_SkZi5Qx"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "BASHKIR=\"$DATA/bashkir\"\n",
    "git clone https://github.com/nevmenandr/bashkir-corpus \"$BASHKIR-corpus\"\n",
    "mkdir \"$BASHKIR\" & mkdir \"$BASHKIR/raw\"\n",
    "find \"$BASHKIR-corpus\" -name \"*.txt\" -print0 | xargs -0 -I file cat file > \"$BASHKIR/ba\"\n",
    "# rm -rf -d  \"$BASHKIR-corpus\"\n",
    "\n",
    "WIKIEXTRACTOR=\"$TOOLS/wikiextractor\"\n",
    "git clone https://github.com/ptakopysk/wikiextractor \"$WIKIEXTRACTOR\"\n",
    "[ -f $BASHKIR/bawiki-latest-pages-articles.xml.bz2 ] || wget http://download.wikimedia.org/bawiki/latest/bawiki-latest-pages-articles.xml.bz2 -P \"$BASHKIR\"\n",
    "python3 \"$WIKIEXTRACTOR/WikiExtractor.py\"  --json -o \"$BASHKIR/ba_wiki\" \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\"\n",
    "# rm \"$BASHKIR/bawiki-latest-pages-articles.xml.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsoRcC-kjRWJ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_folder = os.path.join(os.environ['DATA'], 'bashkir', 'ba_wiki')\n",
    "output_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
    "\n",
    "output_file = open(output_path, \"a+\", encoding='utf-8')\n",
    "\n",
    "for path, subdirs, files in os.walk(input_folder):\n",
    "    for name in files:\n",
    "        file = open(os.path.join(path, name), 'r', encoding='utf-8')\n",
    "        for line in file.readlines():\n",
    "            dump = json.loads(line)\n",
    "            if dump[\"text\"].strip('\\n'):\n",
    "                output_file.write(\"%s\\n\" % dump[\"text\"])\n",
    "        file.close()\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "# !rm -rf -d \"$DATA/bashkir/ba_wiki\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6anyB6mMjdVc"
   },
   "source": [
    "## Russian Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ldp5znAljcrw"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget http://data.statmt.org/wmt17/translation-task/news.2016.ru.shuffled.gz -P \"$DATA\"\n",
    "gzip -d \"$DATA/news.2016.ru.shuffled.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHrDj0mjk7I1"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrekFRqFjTkt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install razdel\n",
    "from razdel import sentenize\n",
    "\n",
    "mono_raw_data_path = os.path.join(os.environ['DATA'], 'bashkir', 'ba')\n",
    "mono_sentenized_data_path = os.path.join(os.environ['DATA'], 'ba.sentesized')\n",
    "\n",
    "def sentenize_raw_data(raw_data_path, sentenized_data_path):\n",
    "    raw_data = open(raw_data_path, 'r', encoding='utf-8')\n",
    "    sentenized_data = open(sentenized_data_path, 'w+', encoding='utf-8')\n",
    "\n",
    "    for line in raw_data:\n",
    "        sentences = sentenize(line)\n",
    "        sentenized_data.writelines([\"%s\\n\" % sentence.text for sentence in sentences if sentence.text.strip()])\n",
    "\n",
    "sentenize_raw_data(mono_raw_data_path, mono_sentenized_data_path)\n",
    "sentenize_raw_data(os.path.join(os.environ['DATA'], os.environ['L1_DATA_PARALLEL_RAW']), os.path.join(os.environ['DATA'], os.environ['L1_DATA_PARALLEL']))\n",
    "sentenize_raw_data(os.path.join(os.environ['DATA'], os.environ['L2_DATA_PARALLEL_RAW']), os.path.join(os.environ['DATA'], os.environ['L2_DATA_PARALLEL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hwcoWrtk_PC"
   },
   "source": [
    "## Text cleaning and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1k8C04l6k6eR"
   },
   "outputs": [],
   "source": [
    "!pip install -U sacremoses\n",
    "from sacremoses import MosesPunctNormalizer, MosesTokenizer\n",
    "\n",
    "def preprocess_file(filepath, language):\n",
    "    normalizer = MosesPunctNormalizer(language, pre_replace_unicode_punct=True, post_remove_control_chars=True)\n",
    "    tokenizer = MosesTokenizer(language)\n",
    "    output_file = open('%s.cleaned' % filepath, 'w+', encoding='utf-8')\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as input_file:\n",
    "        for line in input_file:\n",
    "            line = normalizer.normalize(line)\n",
    "            line.replace(\"&quot;\", '')\n",
    "            tokens = tokenizer.tokenize(line)\n",
    "            if tokens:\n",
    "                output_file.write(\"{}\\n\".format(' '.join(tokens)))\n",
    "\n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L1_DATA']), os.environ['L1']) \n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L2_DATA']), os.environ['L2'])\n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L1_DATA_PARALLEL']), os.environ['L1']) \n",
    "preprocess_file(os.path.join(os.environ['DATA'], os.environ['L2_DATA_PARALLEL']), os.environ['L2']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCz9QlkQlqGx"
   },
   "source": [
    "## BPE codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmJe-ViKloM-"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "FASTBPE=\"$TOOLS/fastBPE\"\n",
    "FAST=\"$FASTBPE/fast\"\n",
    "git clone https://github.com/glample/fastBPE \"$FASTBPE\"\n",
    "g++ -std=c++11 -pthread -O3 \"$FASTBPE/fastBPE/main.cc\" -IfastBPE -o \"$FAST\"\n",
    "\"$FAST\" learnbpe $VOCAB_SIZE \"$DATA/${L1_DATA}.cleaned\" \"$DATA/${L2_DATA}.cleaned\" > \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"${L1_DATA_PREPARED}\" \"$DATA/${L1_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"${L2_DATA_PREPARED}\" \"$DATA/${L2_DATA}.cleaned\" \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"${L1_DATA_PARALLEL_PREPARED}\" \"$DATA/${L1_DATA_PARALLEL}.cleaned\" \"$DATA/BPE_codes\"\n",
    "\"$FAST\" applybpe \"${L2_DATA_PARALLEL_PREPARED}\" \"$DATA/${L2_DATA_PARALLEL}.cleaned\" \"$DATA/BPE_codes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDvvI34mzPnq"
   },
   "source": [
    "## Cross-lingual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rh2I-y4GzPK4"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "FASTTEXT_DIR=\"$TOOLS/fastText\"\n",
    "FASTTEXT=\"$FASTTEXT_DIR/fasttext\"\n",
    "git clone https://github.com/facebookresearch/fastText.git \"$FASTTEXT_DIR\"\n",
    "cd \"$FASTTEXT_DIR\" \n",
    "[ -f \"$FASTTEXT\" ] || make\n",
    "\n",
    "CONCAT_BPE=\"$DATA/concatenated.$VOCAB_SIZE\"\n",
    "N_THREADS=$(grep -c ^processor /proc/cpuinfo)\n",
    "echo $N_THREADS\n",
    "cat \"${L1_DATA_PREPARED}\" \"${L2_DATA_PREPARED}\" | shuf > \"$CONCAT_BPE\"\n",
    "chmod +x \"$FASTTEXT\"\n",
    "\"$FASTTEXT\" skipgram -dim 256 -thread $N_THREADS -input \"$CONCAT_BPE\" -output \"$EMBEDDINGS_DIR/$BPE_EMBEDDINGS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94T9Avacpk8A"
   },
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHzKdvLgplk_"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdN55Q2aEkyi"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "import copy\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#src https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_module_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def get_mask(inputs, pad_mask): #[2]\n",
    "    slen, bs = inputs.size()\n",
    "    lengths = slen-torch.sum(pad_mask, 0)\n",
    "    alen = torch.arange(slen, dtype=torch.long, device=lengths.device)\n",
    "    return alen < lengths[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EB7Wv-lppYL"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wWOxh8XtXCF"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer, \\\n",
    "                     TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  \n",
    "    def __init__(self, field, d_model=256, nlayers=4, nheads=8, dropout=0.1, freeze_embs=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.voc_size = len(field.vocab) \n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dropout = dropout\n",
    "        self.embeddings = nn.Embedding(self.voc_size, d_model).from_pretrained(field.vocab.vectors, freeze=freeze_embs)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, nheads, dim_feedforward=4*d_model, dropout=dropout, activation='gelu')\n",
    "        self.layers = get_module_clones(encoder_layer, nlayers)\n",
    "    \n",
    "    def forward(self, src, pad_mask):\n",
    "        src_mask = get_mask(src, pad_mask)\n",
    "        x = self.embeddings(src)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "      \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask, pad_mask)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIPdFq6Yw-E3"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, fields, encoder, d_model=256, nlayers=4, nheads=8, dropout=0.1, shared_nlayers=2):\n",
    "        \"\"\"\n",
    "        :param fields: list of fields for 0: L1, 1: L2, 2: both\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        assert len(fields) == 3\n",
    "        self.sos_idx = [field.vocab.stoi['<sos>'] for field in fields]\n",
    "        self.eos_idx = [field.vocab.stoi['<eos>'] for field in fields]\n",
    "        self.pad_idx = [field.vocab.stoi['<pad>'] for field in fields]\n",
    "        self.fields = [field for field in fields]\n",
    "        self.d_model = d_model\n",
    "        self.dropout = dropout\n",
    "        self.embeddings = encoder.embeddings\n",
    "        self.pos_encoder = encoder.pos_encoder\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayer(d_model, nheads, dim_feedforward=4*d_model, dropout=dropout, activation='gelu')\n",
    "        self.layers = nn.ModuleList()\n",
    "        shared_layers = get_module_clones(decoder_layer, shared_nlayers)\n",
    "        # Layers for the source language with shared bottom layers\n",
    "        self.layers.append(shared_layers) \n",
    "        self.layers[0].extend(get_module_clones(decoder_layer, nlayers-shared_nlayers))\n",
    "        # Layers for the target language with shared bottom layers\n",
    "        self.layers.append(shared_layers) \n",
    "        self.layers[1].extend(get_module_clones(decoder_layer, nlayers-shared_nlayers))\n",
    "\n",
    "        proj_layers = [nn.Linear(self.embeddings.embedding_dim, len(field.vocab)) for field in fields[:2]]\n",
    "        self.proj_layers = nn.ModuleList(proj_layers)\n",
    "\n",
    "    def forward(self, previous_tokens, encoded, enc_pad_mask, lang_id):\n",
    "        x = self.embeddings(previous_tokens)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "      \n",
    "        for layer in self.layers[lang_id]:\n",
    "            x = layer(x, encoded, memory_key_padding_mask=enc_pad_mask)\n",
    "\n",
    "        x = self.proj_layers[lang_id](x)\n",
    "        return x\n",
    "\n",
    "    def generate_sequence(self, encoded, enc_pad_mask, lang_id, sequence_len=128):\n",
    "        cur_len = 1\n",
    "        bs = encoded.size(1)\n",
    "        decoded = torch.LongTensor(sequence_len, bs).fill_(self.pad_idx[lang_id])\n",
    "        decoded = decoded.to(encoded.device)\n",
    "        decoded_shared = torch.LongTensor(sequence_len, bs).fill_(self.pad_idx[lang_id]).to(encoded.device)\n",
    "        decoded[0] = self.sos_idx[lang_id]\n",
    "        decoded_shared[0] = self.sos_idx[2]\n",
    "        unfinished_sents = torch.LongTensor(bs).fill_(1).to(encoded.device)\n",
    "        \n",
    "        while cur_len < sequence_len:\n",
    "            scores = self.forward(decoded_shared[:cur_len], encoded, enc_pad_mask, lang_id)\n",
    "            scores = scores[-1, :, :]\n",
    "            next_words = torch.topk(scores, 1)[1].squeeze(1).to(encoded.device)\n",
    "            assert next_words.size() == (bs,)\n",
    "\n",
    "            decoded[cur_len] = next_words*unfinished_sents + self.pad_idx[lang_id]*(1-unfinished_sents)\n",
    "            decoded_shared[cur_len] = self.specific_vocab_2_encoder(decoded[cur_len], lang_id)\n",
    "            unfinished_sents.mul_(next_words.ne(self.eos_idx[lang_id]).long())\n",
    "            cur_len += 1\n",
    "\n",
    "            if unfinished_sents.max() == 0:\n",
    "                break\n",
    "\n",
    "        \n",
    "        if cur_len == sequence_len:\n",
    "            decoded[sequence_len - 1].masked_fill_(unfinished_sents.bool(), self.eos_idx[lang_id])\n",
    "            decoded_shared[sequence_len - 1].masked_fill_(unfinished_sents.bool(), self.eos_idx[2])\n",
    "            \n",
    "        return decoded, decoded_shared\n",
    "    \n",
    "    def specific_vocab_2_encoder(self, trg, lang_id):\n",
    "        replace_index = lambda x: self.fields[2].vocab.stoi[self.fields[lang_id].vocab.itos[x]]\n",
    "        return trg.clone().detach().cpu().apply_(replace_index).to(trg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbszYcXVGz8k"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxJWr0cQVRSB"
   },
   "source": [
    "1) https://github.com/pytorch/fairseq/blob/7b3df95f287bc0d844f64fe45717123d06dacb97/fairseq/data/noising.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fAdRiV3bFw4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# [1]\n",
    "class Noising:\n",
    "    def __init__(self, vocab):\n",
    "        \"\"\"\n",
    "        Vocab of encoder input\n",
    "        \"\"\"\n",
    "        self.vocab = vocab\n",
    "        self.bpe_ends_mask = np.array([not vocab.itos[i].endswith('@@') for i in range(len(vocab))])\n",
    "        \n",
    "        self.pad_idx = vocab.stoi['<pad>']\n",
    "        self.sos_idx = vocab.stoi['<sos>']\n",
    "        self.eos_idx = vocab.stoi['<eos>']\n",
    "        self.sep_idx = vocab.stoi['<sep>']\n",
    "        self.mask_idx = vocab.stoi['<mask>']\n",
    "\n",
    "    def noise(self, inp):\n",
    "        x = inp.cpu()\n",
    "        pad_mask = x.eq(self.pad_idx)\n",
    "        lengths = x.size(0) - pad_mask.sum(0)\n",
    "\n",
    "        x = self.shuffle(x, lengths)\n",
    "        x, lengths = self.dropout(x, lengths)\n",
    "        x, lengths = self.dropout(x, lengths, blank_idx=self.mask_idx)\n",
    "        return x\n",
    "\n",
    "    def get_word_idx(self, x):\n",
    "        bpe_end = self.bpe_ends_mask[x]\n",
    "        word_idx = bpe_end[::-1].cumsum(0)[::-1]\n",
    "        word_idx = word_idx.max(0)[None, :] - word_idx \n",
    "        return word_idx\n",
    "\n",
    "    def dropout(self, x, lengths, dropout_rate=0.1, blank_idx=None):\n",
    "        sentences = []\n",
    "        modified_lengths = []\n",
    "        word_idx = self.get_word_idx(x)\n",
    "        sos_mask = x.eq(self.sos_idx)\n",
    "        eos_mask = x.eq(self.eos_idx)\n",
    "        not_dropout_mask = sos_mask + eos_mask\n",
    "        not_dropout_mask = not_dropout_mask.numpy()\n",
    "        \n",
    "        for i in range(lengths.size(0)):\n",
    "            num_words = max(word_idx[:, i]) + 1\n",
    "            keep = np.random.rand(num_words) >= dropout_rate\n",
    "            do_not_dropout_words_idx = word_idx[:, i]*not_dropout_mask[:, i]\n",
    "            keep[do_not_dropout_words_idx] = 1 # do not dropout <sos> symbol\n",
    "            words = x[:lengths[i], i].tolist()\n",
    "            new_s = [\n",
    "                w if keep[word_idx[j, i]] else blank_idx\n",
    "                for j, w in enumerate(words)\n",
    "            ]\n",
    "            new_s = [w for w in new_s if w is not None]\n",
    "            sentences.append(new_s)\n",
    "            modified_lengths.append(len(new_s))\n",
    "        # re-construct input\n",
    "        modified_lengths = torch.LongTensor(modified_lengths)\n",
    "\n",
    "        modified_x = torch.LongTensor(\n",
    "            x.size(0),\n",
    "            x.size(1)\n",
    "        ).fill_(self.pad_idx)\n",
    "        for i in range(modified_lengths.size(0)):\n",
    "            modified_x[:modified_lengths[i], i].copy_(torch.LongTensor(sentences[i]))\n",
    "\n",
    "        return modified_x, modified_lengths\n",
    "\n",
    "    def shuffle(self, x, lengths, max_shuffle_distance=3):\n",
    "        if max_shuffle_distance == 0:\n",
    "            return x\n",
    "        eos_mask = x.eq(self.eos_idx)\n",
    "        lengths -= eos_mask.sum(0)\n",
    "\n",
    "        noise = np.random.uniform(\n",
    "            0,\n",
    "            max_shuffle_distance,\n",
    "            size=(x.size(0), x.size(1)),\n",
    "        )\n",
    "        \n",
    "        sos_mask = x.eq(self.sos_idx).numpy()\n",
    "        do_not_shuffle_indices = np.nonzero(sos_mask)\n",
    "        noise[do_not_shuffle_indices] = -1 # do not move <sos> symbols\n",
    "        word_idx = self.get_word_idx(x)\n",
    "\n",
    "        x2 = x.clone()\n",
    "        for i in range(lengths.size(0)):\n",
    "            scores = word_idx[:lengths[i], i] + noise[word_idx[:lengths[i], i], i]\n",
    "            scores += 1e-6 * np.arange(lengths[i])\n",
    "            permutation = scores.argsort()\n",
    "            x2[:lengths[i], i].copy_(\n",
    "                x2[:lengths[i], i][torch.from_numpy(permutation)]\n",
    "            )\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkWfxbXOvUGB"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch.optim import Adam\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, encoder, decoder, fields, params, logger, clip=1.0, lr=0.0001):\n",
    "        \"\"\"\n",
    "        :param fields: list of fields for 0: L1, 1: L2, 2: both\n",
    "        \"\"\"\n",
    "        self.encoder = encoder.to(params.device)\n",
    "        self.decoder = decoder.to(params.device)\n",
    "\n",
    "        self.pad_idx = [field.vocab.stoi['<pad>'] for field in fields]\n",
    "        self.vocab_sizes = [len(field.vocab) for field in fields]\n",
    "        self.fields = fields\n",
    "\n",
    "        self.criterion = [nn.CrossEntropyLoss(ignore_index=pad_idx) for pad_idx in self.pad_idx[:2]]\n",
    "        self.clip = clip\n",
    "\n",
    "        self.noising = Noising(fields[2].vocab)\n",
    "\n",
    "        self.enc_optimizer = Adam(encoder.parameters(), lr=lr)\n",
    "        self.dec_optimizer = Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "        self.n_total_iter = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.device = params.device\n",
    "        self.logger = logger\n",
    "\n",
    "    def get_denoising_loss_weight(self, init_weight=1, decrease_slower_iter=10**5, weight_slower=0.1, set_to_zero_iter=3*10**5):\n",
    "        if self.n_total_iter < decrease_slower_iter:\n",
    "            return init_weight - ((init_weight-weight_slower)/decrease_slower_iter)*self.n_total_iter\n",
    "\n",
    "        return weight_slower - (weight_slower/(set_to_zero_iter - decrease_slower_iter))*(self.n_total_iter - decrease_slower_iter)\n",
    "    \n",
    "    def backprop(self, loss):\n",
    "        self.enc_optimizer.zero_grad()\n",
    "        self.dec_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.encoder.parameters(), self.clip)\n",
    "        nn.utils.clip_grad_norm_(self.decoder.parameters(), self.clip)\n",
    "        self.enc_optimizer.step()\n",
    "        self.dec_optimizer.step()\n",
    "\n",
    "    def denoising_step(self, inp, specific_vocab_inp, lang_id):\n",
    "        x = self.noising.noise(inp).to(self.device)\n",
    "        pad_mask = x.eq(self.pad_idx[-1]).transpose_(0, 1)\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        encoded = self.encoder(x, pad_mask)\n",
    "        scores = self.decoder(x[:-1], encoded, pad_mask, lang_id)\n",
    "        loss = self.criterion[lang_id](scores.view(-1, self.vocab_sizes[lang_id]), specific_vocab_inp[1:].view(-1))\n",
    "\n",
    "        loss = self.get_denoising_loss_weight() * loss\n",
    "\n",
    "        self.backprop(loss)\n",
    "\n",
    "        progress_state = OrderedDict(\n",
    "            step_type='denoising',\n",
    "            loss=loss.item(),\n",
    "            sentences=inp.size(1),\n",
    "            n_total_iter=self.n_total_iter,\n",
    "            epoch=self.epoch,\n",
    "            lang_id=lang_id\n",
    "            )\n",
    "\n",
    "        return progress_state\n",
    "\n",
    "    def backtranslation_step(self, src, specific_vocab_src, trg, src_lang_id, trg_lang_id):\n",
    "        # src -> trg -> src\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "\n",
    "        trg_pad_mask = trg.eq(self.pad_idx[-1]).transpose_(0, 1)\n",
    "        encoded = self.encoder(trg, trg_pad_mask)\n",
    "\n",
    "        src_pad_mask = src.eq(self.pad_idx[-1]).transpose_(0, 1)\n",
    "        scores = self.decoder(src[:-1], encoded, src_pad_mask, src_lang_id)\n",
    "        loss = self.criterion[src_lang_id](scores.view(-1, self.vocab_sizes[src_lang_id]), specific_vocab_src[1:].view(-1))\n",
    "\n",
    "        self.backprop(loss)\n",
    "\n",
    "        progress_state = OrderedDict(\n",
    "            step_type='backtranslation',\n",
    "            loss=loss.item(),\n",
    "            sentences=src.size(1),\n",
    "            n_total_iter=self.n_total_iter,\n",
    "            epoch=self.epoch,\n",
    "            backtranslation_direction='{}->{}->{}'.format(src_lang_id, trg_lang_id, src_lang_id)\n",
    "            )\n",
    "        \n",
    "        return progress_state\n",
    "        \n",
    "    def generate_translation(self, src, lang1_id, lang2_id, train=True):\n",
    "        pad_mask = src.eq(self.pad_idx[-1]).transpose_(0, 1)\n",
    "\n",
    "        if train:\n",
    "            encoded = self.encoder(src, pad_mask)          \n",
    "            trg, trg_shared = self.decoder.generate_sequence(encoded, pad_mask, lang2_id) \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                encoded = self.encoder(src, pad_mask)          \n",
    "                trg, trg_shared = self.decoder.generate_sequence(encoded, pad_mask, lang2_id) \n",
    "\n",
    "        return trg, trg_shared\n",
    "\n",
    "    def save_model(self, dump_dir, name):\n",
    "        path = os.path.join(dump_dir, '%s.pth' % name)\n",
    "        self.logger.log('Saving model to %s ...' % path)\n",
    "        torch.save({\n",
    "            'encoder': self.encoder,\n",
    "            'decoder': self.decoder,\n",
    "            'enc_optimizer': self.enc_optimizer,\n",
    "            'dec_optimizer': self.dec_optimizer,\n",
    "            'epoch': self.epoch,\n",
    "            'n_total_iter': self.n_total_iter, \n",
    "            'criterion': self.criterion\n",
    "        }, path)\n",
    "\n",
    "        \n",
    "def reload_checkpoint(dump_dir, name, fields, params, logger):\n",
    "    checkpoint_path = os.path.join(dump_dir, name)\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        return\n",
    "\n",
    "    logger.log('Reloading checkpoint from %s ...' % checkpoint_path)\n",
    "    checkpoint_data = torch.load(checkpoint_path)\n",
    "    encoder = checkpoint_data['encoder']\n",
    "    decoder = checkpoint_data['decoder']\n",
    "    trainer = Trainer(encoder, decoder, fields, params, logger)\n",
    "    trainer.enc_optimizer = checkpoint_data['enc_optimizer']\n",
    "    trainer.dec_optimizer = checkpoint_data['dec_optimizer']\n",
    "    trainer.epoch = checkpoint_data['epoch']\n",
    "    trainer.n_total_iter = checkpoint_data['n_total_iter'] + 1\n",
    "    trainer.criterion = checkpoint_data['criterion']\n",
    "\n",
    "    logger.log('Checkpoint reloaded. Resuming at epoch %i ...' % trainer.epoch)\n",
    "    print('Checkpoint reloaded. Resuming at epoch %i ...' % trainer.epoch)\n",
    "\n",
    "    return encoder, decoder, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Heohu9eLfie1"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext\n",
    "from torchtext import data\n",
    "\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, path, fields, newline_eos=True,\n",
    "                 encoding='utf-8', **kwargs):\n",
    "        fields_ = [('encoder_text', fields[0]), ('specific_text', fields[1])]\n",
    "        with open(path, encoding=encoding) as f:\n",
    "            sentences = [fields[0].preprocess(line) for line in f if line.strip('\\n')]        \n",
    "        examples = [data.Example.fromlist([sentence, sentence], fields_) for sentence in sentences]\n",
    "        super(CustomDataset, self).__init__(\n",
    "            examples, fields_, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator, metrics\n",
    "from torchtext.datasets import TranslationDataset\n",
    "\n",
    "class Evaluation:\n",
    "    \n",
    "    SPECIAL_TOKENS = ['<pad>', '<eos>', '<sos>']\n",
    "    \n",
    "    def __init__(self, path, exts, fields, trainer, params):\n",
    "        \"\"\"\n",
    "        :param path: Common prefix of paths to the data files for both languages\n",
    "        :param exts: A tuple containing the extension to path for each language\n",
    "        :param fields: 0: L1, 1: L2, 2: both\n",
    "        \"\"\"\n",
    "        self.fields = fields\n",
    "        self.dataset = TranslationDataset(path, exts, (fields[2], fields[2]))\n",
    "        self.iter = BucketIterator(dataset=self.dataset, batch_size=32)\n",
    "        self.trainer = trainer\n",
    "        self.device = params.device\n",
    "\n",
    "    def calculate_score(self, src_lang=0, trg_lang=1):\n",
    "        translations = []\n",
    "        reference = []\n",
    "        for batch in self.iter:\n",
    "            results, _ = self.trainer.generate_translation(batch.src.to(self.device), src_lang, trg_lang)\n",
    "            translations += [[self.fields[trg_lang].vocab.itos[token] for token in sentence] for sentence in results.T]\n",
    "            reference += [[self.fields[2].vocab.itos[token] for token in sentence] for sentence in batch.trg.T]\n",
    "            \n",
    "        translations = [[token for token in sentence if token not in self.SPECIAL_TOKENS] for sentence in translations]\n",
    "        reference = [[token for token in sentence if token not in self.SPECIAL_TOKENS] for sentence in reference]\n",
    "\n",
    "        return metrics.bleu_score(translations, reference), translations, reference\n",
    "\n",
    "    def generate_translation(self, sentence, src_lang, trg_lang):\n",
    "        x = self.fields[src_lang].preprocess(sentence)\n",
    "        x = self.fields[src_lang].process([x]).to(self.device)\n",
    "        translation, _ = self.trainer.generate_translation(x, src_lang, trg_lang, train=False)\n",
    "        translation = [self.fields[trg_lang].vocab.itos[token] for token in translation]\n",
    "        translation_str = ''\n",
    "        for token in translation:\n",
    "            if token in self.SPECIAL_TOKENS:\n",
    "                continue\n",
    "            if token.endswith(\"@@\"):\n",
    "                translation_str += token[:-2]\n",
    "                continue\n",
    "            translation_str += token + ' '\n",
    "\n",
    "        return translation_str\n",
    "    \n",
    "    def shared_2_specific(self, trg, lang_id):\n",
    "        replace_index = lambda x: self.fields[lang_id].vocab.stoi[self.fields[2].vocab.itos[x]]\n",
    "        return trg.clone().detach().cpu().apply_(replace_index).to(trg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGK7SE2MGyzn"
   },
   "outputs": [],
   "source": [
    "!pip install dill\n",
    "import dill\n",
    "from itertools import zip_longest\n",
    "from torchtext.datasets import LanguageModelingDataset\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, path=None):\n",
    "          self.log_file = open(path, 'a+') if path else None\n",
    "\n",
    "    def log(self, info):\n",
    "        if type(info) is str:\n",
    "            print(\"%s\\n\" % info, file=self.log_file)\n",
    "        elif type(info) is OrderedDict:\n",
    "            for k, v in info.items():\n",
    "                print(\"%s: \" % str(k), file=self.log_file)\n",
    "                print(\"%s\\n\" % str(v), file=self.log_file)\n",
    "\n",
    "            print('\\n\\n\\n', file=self.log_file)\n",
    "\n",
    "    def close(self):\n",
    "        if self.log_file:\n",
    "            self.log_file.close()\n",
    "\n",
    "\n",
    "def main(params):\n",
    "    logger = Logger(params.log_file)\n",
    "\n",
    "    if os.path.isfile(params.field_path):\n",
    "        with open(params.field_path,\"rb\")as f:\n",
    "            TEXT = dill.load(f)\n",
    "        with open('{}.{}'.format(params.field_path, params.l1),\"rb\")as f:\n",
    "            TEXT_L1 = dill.load(f)\n",
    "        with open('{}.{}'.format(params.field_path, params.l2),\"rb\")as f:\n",
    "            TEXT_L2 = dill.load(f)\n",
    "    else:\n",
    "        assert params.train\n",
    "        vectors = Vectors(name=params.embs_file, cache=params.embs_dir) \n",
    "        logger.log(\"Loaded Vectors\")\n",
    "    \n",
    "        TEXT = data.Field(\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            fix_length=params.sequence_length\n",
    "        )\n",
    "\n",
    "        TEXT_L1 = data.Field(\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            fix_length=params.sequence_length\n",
    "        )\n",
    "        \n",
    "        TEXT_L2 = data.Field(\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            fix_length=params.sequence_length\n",
    "        )\n",
    "        logger.log(\"Loaded Field\")\n",
    "        \n",
    "        \n",
    "    if params.train:\n",
    "        train_l1_dataset = CustomDataset(params.l1_data_path, (TEXT, TEXT_L1))\n",
    "        logger.log(\"Loaded L1 Dataset\")\n",
    "        train_l2_dataset = CustomDataset(params.l2_data_path, (TEXT, TEXT_L2))\n",
    "        logger.log(\"Loaded L2 Dataset\")\n",
    "\n",
    "        if not os.path.isfile(params.field_path):\n",
    "            TEXT.build_vocab(\n",
    "                train_l1_dataset,\n",
    "                train_l2_dataset,\n",
    "                specials=['<sep>', '<mask>'],\n",
    "                vectors=vectors\n",
    "            )\n",
    "                   \n",
    "            TEXT_L1.build_vocab(\n",
    "                train_l1_dataset,\n",
    "                specials=['<sep>', '<mask>']\n",
    "            )\n",
    "                   \n",
    "            TEXT_L2.build_vocab(\n",
    "                train_l2_dataset,\n",
    "                specials=['<sep>', '<mask>']\n",
    "            )\n",
    "                                       \n",
    "            with open(params.field_path,\"wb\")as f:\n",
    "                dill.dump(TEXT,f)\n",
    "            with open('{}.{}'.format(params.field_path, params.l1),\"wb\")as f:\n",
    "                dill.dump(TEXT_L1,f)\n",
    "            with open('{}.{}'.format(params.field_path, params.l2),\"wb\")as f:\n",
    "                dill.dump(TEXT_L2,f)\n",
    "                                \n",
    "        l1_iter = data.BucketIterator(\n",
    "              dataset = train_l1_dataset,\n",
    "              batch_size = params.batch_size,\n",
    "              shuffle=True,\n",
    "              device=params.device\n",
    "        )\n",
    "        logger.log(\"Created L1 Iterator\")\n",
    "\n",
    "        l2_iter = data.BucketIterator(\n",
    "              dataset = train_l2_dataset,\n",
    "              batch_size = params.batch_size,\n",
    "              shuffle=True,\n",
    "              device=params.device\n",
    "        )\n",
    "        logger.log(\"Created L2 Iterator\")\n",
    "\n",
    "    \n",
    "    if params.checkpoint:\n",
    "        encoder, decoder, trainer = reload_checkpoint(params.dump_dir, params.checkpoint, [TEXT_L1, TEXT_L2, TEXT], params, logger)    \n",
    "    else:\n",
    "        encoder = Encoder(TEXT)\n",
    "        logger.log(\"Created Encoder\")\n",
    "        decoder = Decoder([TEXT_L1, TEXT_L2, TEXT], encoder)\n",
    "        logger.log(\"Created Decoder\")\n",
    "\n",
    "        trainer = Trainer(encoder, decoder, [TEXT_L1, TEXT_L2, TEXT], params, logger)\n",
    "        logger.log(\"Created Trainer\")\n",
    "\n",
    "        if params.train:\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "    \n",
    "    languages = {params.l1: 0, params.l2: 1}\n",
    "    \n",
    "    evaluation = Evaluation(os.environ[\"PARALLEL_PREFIX\"], languages.keys(), [TEXT_L1, TEXT_L2, TEXT], trainer, params)\n",
    "    \n",
    "    if not params.train:\n",
    "        logger.log(\"BLEU score: \", evaluation.calculate_score())\n",
    "    \n",
    "    logger.log(\"===================TRAINING STARTED===================\")\n",
    "    while trainer.epoch <= params.n_epoch:\n",
    "        logger.log(\"===================EPOCH%d===================\" % trainer.epoch)\n",
    "        for batches in zip_longest(l1_iter, l2_iter, fillvalue=None):\n",
    "            print(f'\\rIteration {trainer.n_total_iter}')\n",
    "            for src_id in languages.values():\n",
    "                if not batches[src_id]: # if there are no batches for this language\n",
    "                    continue\n",
    "                trg_id = 0 if src_id == 1 else 1 \n",
    "                src_text = batches[src_id].encoder_text # using field with joint vocab\n",
    "                src_specific_text = batches[src_id].specific_text # using field with specific vocabulary \n",
    "                denoising_progress_state = trainer.denoising_step(src_text, src_specific_text, src_id)\n",
    "                _, translation_shared = trainer.generate_translation(src_text, src_id, trg_id)\n",
    "                bt_progress_state = trainer.backtranslation_step(src_text, src_specific_text, translation_shared, src_id, trg_id)\n",
    "        \n",
    "            if trainer.n_total_iter and trainer.n_total_iter % params.save_every_ith_iter == 0:\n",
    "                trainer.save_model(params.dump_dir, 'checkpoint-{}-{}'.format(trainer.epoch, trainer.n_total_iter))            \n",
    "                logger.log(denoising_progress_state)\n",
    "                logger.log(bt_progress_state)\n",
    "                logger.log(\"Epoch {} BLEU score: {}\".format(trainer.epoch, evaluation.calculate_score()))\n",
    "            trainer.n_total_iter += 1\n",
    "\n",
    "        trainer.epoch += 1\n",
    "\n",
    "    log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VW-iwnyek4Jq"
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        # Embeddings\n",
    "        self.embs_file = \"%s.vec\" % os.environ[\"BPE_EMBEDDINGS\"]\n",
    "        self.embs_dir = os.environ[\"EMBEDDINGS_DIR\"]\n",
    "\n",
    "        # Dataset\n",
    "        self.l1 = os.environ['L1']\n",
    "        self.l2 = os.environ['L2']        \n",
    "        self.l1_data_path = os.environ[\"L1_DATA_PREPARED\"]\n",
    "        self.l2_data_path = os.environ[\"L2_DATA_PREPARED\"]\n",
    "\n",
    "        self.l1_parallel_path = os.environ[\"L1_DATA_PARALLEL_PREPARED\"]\n",
    "        self.l2_parallel_path = os.environ[\"L2_DATA_PARALLEL_PREPARED\"]\n",
    "        \n",
    "        self.l1_data_path = os.environ[\"L1_DATA_PREPARED\"] + '.cut'\n",
    "        self.l2_data_path = os.environ[\"L2_DATA_PREPARED\"] + '.cut'\n",
    "\n",
    "        # Training\n",
    "        self.sequence_length = 128\n",
    "        self.batch_size = 48\n",
    "        self.lr = 0.0001\n",
    "        self.clip = 1.0\n",
    "\n",
    "        self.n_epoch = 40\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.log_file = os.path.join(os.environ['MODELS'], 'log_1.txt')\n",
    "        self.dump_dir = os.environ['MODELS']\n",
    "        self.field_path = os.path.join(os.environ['MODELS'], 'TEXT.field')\n",
    "\n",
    "        self.vocab_size = os.environ['VOCAB_SIZE']\n",
    "\n",
    "        self.save_every_ith_iter = 1000\n",
    "        self.checkpoint = None\n",
    "\n",
    "        self.train = True\n",
    "\n",
    "params = Parameters()\n",
    "main(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSSU50AQKOSw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N7nc2eI__eDx"
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0o9MFgfC_eD2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcNcIw2U_eD5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNMT ba-ru.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
